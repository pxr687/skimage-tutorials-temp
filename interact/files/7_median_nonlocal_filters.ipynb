{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2019d0ea",
   "metadata": {},
   "source": [
    "# More filters: the median filter and non-local filters\n",
    "\n",
    "This page will cover filters which do not use convolution kernels. First, we will look at the median filter, which differs in important ways from the other local filters we saw on [previous](5_mean_filter) pages, because it cannot be implemented through convolution.\n",
    "\n",
    "After the median filter, we will look at another filter, the histogram equalisation filter, which does not use convolution. In fact, histogram equalisation does not use a kernel at all. Because it eschews kernels completely, the histogram equalisation filter is a *non-local* filter. More on this below.\n",
    "\n",
    "As normal, we begin with some imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ff4351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage as ndi\n",
    "import skimage as ski\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Set 'gray' as the default colormap\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Set NumPy precision to 2 decimal places\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "#  A custom function to quickly report image attributes.\n",
    "from show_attributes import show_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b09eb2",
   "metadata": {},
   "source": [
    "# Local filtering without convolution\n",
    "\n",
    "When compared to the other local filters we have seen, the median filter uses the same process of \"walking\" through the image with a small array which denfines the \"local neighbourhood\" of each pixel. In median filtering, you can *loosely* think of this small array as a kernel, but there are some major differences in the calculations, so let's call it the \"neighbourhood array\" instead. \n",
    "\n",
    "Like with the other kernels we have seen, the \"neighbourhood array\" is centered on every pixel during the filtering operation. The central pixel value is replaced with a number computed from the other values in the local neighbourhood, e.g. the other pixel values under the \"neighbourhood array\".  However, instead of *convolving* the neighbourhood array and the image, as we would for a mean filter or Gaussian filter etc., the median filter, shockingly, takes the median value of the pixels under the small array. \n",
    "\n",
    "![](images/kernel_general.png)\n",
    "\n",
    "There is no convolvable function to calculate the median, and this is why [some people](https://dsp.stackexchange.com/questions/13211/convolution-kernels-for-image-filtering) will tell you not to call the \"neighbourhood array\" a \"kernel\", when we are doing median filtering. Calculating the median utilizes ranking and indexing, and cannot be expressed as set of additions, subtractions, multiplications, divisions etc, in the way that calculating a mean can, for instance.\n",
    "\n",
    "One way to think of this, is that when we write the formula for the mean, we can write it without reference to any Python indexing operations:\n",
    "\n",
    "$ \\large \\text{mean} = \\frac{\\sum X}{n} $\n",
    "\n",
    "...we can read that as \"to get the mean of a set of numbers (where $X$ refers all of the numbers), add them up and divide by however many numbers there are ($n$)\". \n",
    "\n",
    "Conversely for the median we first have to order the numbers from lowest to highest ($X_{\\text{sorted}}$), and then find the value that is *at the central index*. So where $X$ is an array containing all the numbers, if $n$ is odd:\n",
    "\n",
    "$ \\large \\text{median} = X_{\\text{sorted}}[\\frac{n}{2}]$\n",
    "\n",
    "Where the square brackets are a *Python* indexing operation (we will need a different indexing operation if using a programming language that does not count indexes from 0, or if $n$ is even...). So for the numbers in the array below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd3e268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some numbers.\n",
    "nums = np.array([10, 4, 5, 8, 7])\n",
    "\n",
    "nums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2f4c6b",
   "metadata": {},
   "source": [
    "We get the mean from: $ \\large \\text{mean} = \\frac{\\sum x_i...x_n}{n} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51005100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the sum, divide by n.\n",
    "np.sum(nums)/len(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331ef9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to the same calculation from NumPy.\n",
    "nums.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefe4d96",
   "metadata": {},
   "source": [
    "Whereas we get the median from: $ \\large \\text{median} = X_{\\text{sorted}}[\\frac{n}{2}]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c274d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the median.\n",
    "sorted_nums = np.sort(nums) # Sort the values, low to high.\n",
    "print(f\"Sorted `nums`: {sorted_nums}\")\n",
    "median = sorted_nums[int(len(sorted_nums)/2)] # Index to get the median.\n",
    "\n",
    "# Show the median value.\n",
    "median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5705c585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to NumPy.\n",
    "np.median(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686cd6c7",
   "metadata": {},
   "source": [
    "There is no convolution kernel that can do this - instead we use the \"neighbourhood array\" to define a pixel neighbourhood, then replace the central value with the median from that neighbourhood, using the sorting and indexing we have seen above. So, the median filter *is* a local filter, because it alters pixel values based on other pixel values in the local neighbourhood. However, it is not a *convolution filter* because it does use the local neighbourhood in a convolution operation, in contrast to other local filters like the mean filter, Gaussian filter etc. \n",
    "\n",
    "# Edge preservation\n",
    "\n",
    "The median filter is especially useful for removing noise from images, while preserving the \"edges\" in the image. You'll recall that the edges are big changes in the gradient of pixel intensities, between nearby pixels (e.g. black-to-white, white-to-black etc). Let's look at why the median filter is \"edge preserving\", by expanding the `nums` array into a low-resolution image, using `np.tile()` and `.reshape()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8a6b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make `nums` into a image array.\n",
    "nums_img = np.tile(nums, reps=3).reshape((3, 5))\n",
    "nums_img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f1c2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show as an image.\n",
    "plt.matshow(nums_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b19fe62",
   "metadata": {},
   "source": [
    "Now, imagine we \"walk\" a 3-by-3 kernel (sorry pedants!) through the `nums_img` array, and replace the central pixel of each kernel (sorry again, pedants!) with the median of the pixels under the kernel.\n",
    "\n",
    "This process is shown below, for three kernels (OK, pedants, three \"local neighbourhoods under a 3-by-3 array very much resembling a kernel\"). The central pixel is highlighted in red, and the index of the current local neighbourhood is shown above the pixel values.\n",
    "\n",
    "The flattened and sorted values from each local neighbourhood are also shown, along with the median value of the neighbourhood:\n",
    "\n",
    "![](images/median_filter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1c9490",
   "metadata": {},
   "source": [
    "We can also show this in \"Python space\", using a for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178ef6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some local neighbourhoods of `nums_img` and their medians.\n",
    "for i in np.arange(3):\n",
    "    i_row_start, i_col_start = 0, i\n",
    "    i_row_end, i_col_end = 3, i+3\n",
    "    print(f\"\\nnums_img[{i_row_start}:{i_row_end}, {i_col_start}:{i_col_end}]\")\n",
    "    current_selection = nums_img[i_row_start:i_row_end, i_col_start:i_col_end]\n",
    "    print(current_selection)\n",
    "    print(f\"Flattened and sorted: {np.sort(current_selection.ravel())}\")\n",
    "    print(f\"Median = {np.median(nums_img[i_row_start:i_row_end, i_col_start:i_col_end])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51956a34",
   "metadata": {},
   "source": [
    "Because the median is not a function which can be applied via convolution, we cannot apply it using `ndi.correlate()`, as we did with the other [local filters](5_mean_filter). \n",
    "\n",
    "We can apply it in `skimage` using `ski.filters.median()`. Again,  we supply a `footprint` argument to determine the size of each pixel's \"local neighbourhood\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99360c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median filter `nums_img`.\n",
    "nums_median_filtered = ski.filters.median(nums_img, \n",
    "                                          footprint=np.ones((3,3)))\n",
    "nums_median_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386dd98d",
   "metadata": {},
   "source": [
    "Compare to the original `nums_img` array below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c543bdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e9eee0",
   "metadata": {},
   "source": [
    "The effect of the \"edges\" of the image is easier to see graphically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a18f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the images.\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(nums_img)\n",
    "plt.title('Original')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(nums_median_filtered)\n",
    "plt.title('Median Filtered');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af42124d",
   "metadata": {},
   "source": [
    "Edges involving a bigger gradient have been preserved, whilst less prominent edges have been merged into more prominent ones. We show this, for comparison, alongside a mean filtered version of `nums_img`, filtered using the same size `footprint` ((3, 3)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2db1cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_img = ski.util.img_as_ubyte(nums_img) # Avoid `dtype` warning.\n",
    "nums_mean_filtered = ski.filters.rank.mean(nums_img,\n",
    "                                           footprint=np.ones((3,3)))\n",
    "# Show the images.\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(nums_img)\n",
    "plt.title('Original')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(nums_median_filtered)\n",
    "plt.title('Median Filtered')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(nums_mean_filtered)\n",
    "plt.title('Mean Filtered');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5391d39e",
   "metadata": {},
   "source": [
    "You can see that the median filter gives a better \"summary\" of the distribution of edges in the original image - the mean filter has spread the edges around more, which makes sense, given that it averages pixels within a kernel. \n",
    "\n",
    "In a higher resolution image, the median filter can have the effect of removing noise whilst preserving edges to a greater extent than some other filters. We will demonstrate the median filter again with the `brick` image from `ski.data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759ca12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the `brick` image.\n",
    "brick = ski.data.brick()\n",
    "show_attributes(brick)\n",
    "plt.imshow(brick);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c890e568",
   "metadata": {},
   "source": [
    "We will also filter `brick` using a mean filter, with the same size kernel as the median filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1a82b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a median filter.\n",
    "median_filtered_brick = ski.filters.median(brick, \n",
    "                                           footprint=np.ones((9,9)))\n",
    "\n",
    "mean_filtered_brick = ski.filters.rank.mean(brick, \n",
    "                                            footprint=np.ones((9,9)))\n",
    "# Plot both image to compare\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(brick)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Median Filtered')\n",
    "plt.imshow(median_filtered_brick)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Mean Filtered')\n",
    "plt.imshow(mean_filtered_brick);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438b83b8",
   "metadata": {},
   "source": [
    "You can see that the edges in the images (transitions between pixels of very different intensities - in this case between the dark bricks and the lighter mortar lines) are less smoothed by the median filter than by the mean filter. This is considered a desirable property of the median filter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57e08d2",
   "metadata": {},
   "source": [
    "# Non-local filters\n",
    "\n",
    "Whilst the median filter does not use convolution, it is still a local filter, because it filters pixels based on the values of other pixels in the local neighbourhood. Other filters use neither convolution nor a local pixel neighbourhood. These filters are called *non-local filters*. \n",
    "\n",
    "Non-local filters have their name because they filter all of the pixels in an image based on characteristics of a specific region of the image, or based upon characteristics of the entire image. As a result, a non-local filter might modify a given pixel's value based on the values of pixels in a region of the image which is nowhere near the \"local neighbourhood\" of the pixel being modified.\n",
    "\n",
    "One foundational non-local filter is a [*histogram equalisation filter*](https://en.wikipedia.org/wiki/Histogram_equalization). This filter modifies pixels based on the histogram of the entire image. Essentially, this process \"smoothes out\" the histogram into a even \"hill\", so that there is less variance between the pixel intensities. The image below illustrates this principle:\n",
    "\n",
    "![](images/hist_equal.png)\n",
    "\n",
    "We will demonstrate the histogram equalisation filter with the `eagle` image from `ski.data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2739f28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the `eagle` image.\n",
    "eagle = ski.data.eagle()\n",
    "show_attributes(eagle)\n",
    "plt.imshow(eagle);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877b80ac",
   "metadata": {},
   "source": [
    "Let's first view the histogram of `eagle`, before we apply the filter. As we know, we can use the `.ravel()` array method to flatten this 2D image to 1D, and then inspect a histogram of the pixel intensities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bceedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatted to 1D.\n",
    "one_D_eagle = eagle.ravel()\n",
    "\n",
    "# Show a histogram.\n",
    "plt.hist(eagle.ravel(), \n",
    "         bins=128)\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Pixel Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe56b2a",
   "metadata": {},
   "source": [
    "In order to apply the histogram equalisation filter, we first \"deconstruct\" into separate arrays using `np.histogram()`. This returns two arrays. One array we will call `counts`; this contains the height of the histogram within each $x$-axis bin. The second array we will call `bin_intervals`; adjacent values in this array are the start and end points of each $x$-axis bin. We use `bin_intervals` to calculate the centerpoint of each bin, by taking the average of the adjacent values.\n",
    "\n",
    "*Note*: alternatively we could use `ski.exposure.histogram()`, to the same effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abff780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centers and bin intervals, from the histogram of the flattened `eagle` image.\n",
    "counts, bin_intervals = np.histogram(one_D_eagle,\n",
    "                                     bins=256)\n",
    "\n",
    "# Calculate the bin centers.\n",
    "bin_centers = (bin_intervals[1:] + bin_intervals[:-1]) / 2\n",
    "\n",
    "# Show the `counts` and `bin_centers`.\n",
    "print(f\"\\nCounts:\\n {counts}\")\n",
    "print(f\"\\nBin centers:\\n {bin_centers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e1259e",
   "metadata": {},
   "source": [
    "We chose to use 256 bins, for this histogram, for reasons that will become apparent further down the page (remember this!).\n",
    "\n",
    "There are several steps in equalising the histogram:\n",
    "\n",
    "- First, we normalise the histogram, so that the counts sum to 1. We do this by dividing each count by the total number of pixels in the image, which converts each count to a proportion.\n",
    "\n",
    "- Then we calculate the *cumulative density* of the normalised histogram. Basically, this means we add up the proportions as we go along the $x$-axis, so each bin indicates the total proportion of pixels up to that point (e.g. pixels in that particular bin, or bins situated lower down the $x$-axis). \n",
    "\n",
    "- We then \"map\" each pixel intensity value to its corresponding cumulative proportion. After this \"mapping\", we have our equalised histogram.\n",
    "\n",
    "This may all sound quite abstract, but bear with us. It is easier to follow in code, and is a visually striking effect when we compare the resulting histogram to the original. \n",
    "\n",
    "For the first step, we can normalise the `counts` by dividing each individual count by the total number of pixels in the image. Note that we could also do this using the optional `density=True` argument to `np.histogram()`, but we do it manually to show what the actual operations involve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4874d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centers and bin intervals, from the histogram of the flattened `eagle` image.\n",
    "n_pixels = len(one_D_eagle) # Get the total number of pixels.\n",
    "counts_normed = counts/n_pixels # Normalize by dividing each count by the total number of pixels.\n",
    "plt.plot(bin_centers, counts_normed)\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Pixel Probability');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f783925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the `counts` sum to 1?\n",
    "print(f\"\\nCounts Normalized sum:\\n {counts_normed.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb21a931",
   "metadata": {},
   "source": [
    "When we equalise the histogram, we want it to be roughly uniform across the pixel intensities. As a tool to perform this \"uniformization\", we first we calculate the cumulative distribution (`cdf`) of the histogram. To do this we take cumulative sum of the normalised counts (`counts_normed`). For a given bin, the cumulative sum operation adds up the proportion of pixels that are in that bin and in all of the lower bins (e.g. the bins closer to 0 on the $x$-axis). Essentially it is a running total of the `counts_normed` as we move from left to right across the $x$-axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fe7e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the cumulative distribution of the pixel intensities.\n",
    "cdf = counts_normed.cumsum() \n",
    "\n",
    "# Show a plot of the cumulative distribution.\n",
    "plt.plot(bin_centers, cdf)\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Cumulative Proportion');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f944e600",
   "metadata": {},
   "source": [
    "The final value in `cdf` is 1 (or at least damn near close, given precision loss in the calculations). Remember, we are adding up proportions here, so a value of 1 indicates that the final bin and all of the lower bins together contain 100% of the pixels in the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b83552",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0936302",
   "metadata": {},
   "source": [
    "The next step requires some thought, to follow what is going on. We want to \"map\" the pixel values in the flattened `one_D_eagle` array to the values in the `cdf`. We can do this, for the current `eagle` image, by using the `one_D_eagle` pixel intensity values as *indexes* for the `cdf` array. This might seem like a hack, so lets break it down.\n",
    "\n",
    "Recall that we asked you to remember that we asked `np.histogram()` to give us a histogram with 256 bins? Well, as a result our `cdf` array, which contains the running total of the proportions in a given bin and lower bins, has 256 elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3116b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the `shape` of the `cdf` array.\n",
    "cdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907e4260",
   "metadata": {},
   "source": [
    "Because we count from 0, when indexing arrays, the final value in `cdf` is at index location 255:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600402ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the final value of the `cdf` array, at integer index location 255.\n",
    "cdf[255]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca65d05",
   "metadata": {},
   "source": [
    "Given that `one_D_eagle` is in the `uint8` `dtype`, the maximum value allowed is 255, and the minimum is 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930810e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the `dtype` and `min`/`max` values of `eagle`.\n",
    "show_attributes(one_D_eagle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca67eeba",
   "metadata": {},
   "source": [
    "Conveniently here, each pixel intensity value in `one_D_eagle` will work as an index into `cdf`. This allows us to replace each pixel intensity value with its corresponding cumulative proportion. So, if a pixel intensity value $p$ falls in bin $b$, then bin $b$ has a corresponding cumulative proportion in the `cdf` array. We use this \"mapped\" values as our output image - this has the effect of \"smoothing out\", or, in fact, \"equalising\" the histogram, because bins without many pixels in them \"inherit\" the proportions from lower bins. Again, this is easier to appreciate visually, by viewing the histograms below.\n",
    "\n",
    "Let's perform the indexing/equalisation, and then inspect the histograms, so this effect becomes apparent. We show this mapping first with ten pixel intensity values from `one_D_eagle`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9c7472",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_ten_pixels = one_D_eagle[:10]\n",
    "first_ten_pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b6ed97",
   "metadata": {},
   "source": [
    "...we then show the corresponding cumulative proportions that these values will be mapped to, when we use them as indexes for `cdf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e70094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf[first_ten_pixels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf4b9bb",
   "metadata": {},
   "source": [
    "To perform this mapping for *every* pixel intensity value, we use the following operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3c9d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equalise the histogram of `eagle`, by using the pixel intensity values in `one_D_eagle` (1 - 255)\n",
    "# as indexes into the `cdf` array.\n",
    "equalised_hist = cdf[one_D_eagle]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5c2c58",
   "metadata": {},
   "source": [
    "The original histogram and the equalised histogram, along with the corresponding images, are shown below. We first `.reshape()` the `equalised_hist` back into the shape of the original, non-flattened `eagle` image, thus restoring its status as a 2D image array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b040c5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to 2D.\n",
    "eagleback_to_2D = equalised_hist.reshape(eagle.shape)\n",
    "\n",
    "# Generate the plot.\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(eagle)\n",
    "plt.title('Original Image')\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title('Original Histogram')\n",
    "plt.hist(eagle.ravel(), bins=128)\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(eagleback_to_2D)\n",
    "plt.title('Equalised Image')\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title('Equalised Histogram')\n",
    "plt.hist(eagleback_to_2D.ravel());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce65ba3c",
   "metadata": {},
   "source": [
    "The equalised histogram now much more closely resembles a [uniform distribution](https://en.wikipedia.org/wiki/Uniform_distribution) - the notable \"peaks and valleys\" of the original and been replaced with a uniform block. The effect on the perceived visual image is one of heightened contrast - pay particular attention to the wall behind the noble eagle. Each image, without the histograms, can be viewed below, for easier inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f80538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the plot.\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(eagle)\n",
    "plt.title('Original Image')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(eagleback_to_2D)\n",
    "plt.title('Equalised Image');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91510628",
   "metadata": {},
   "source": [
    "Obviously, this operation has changed the `dtype` of the image because we have replaced values ranging from 1 to 255 with proportions ranging from 0 to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695412d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `dtype` and `min`/`max` values of the original image.\n",
    "show_attributes(eagle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cdf6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `dtype` and `min`/`max` values of the filtered image.\n",
    "show_attributes(equalised_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9dd676",
   "metadata": {},
   "source": [
    "This is important to be aware of, but we can easily convert back to the original `dtype` using the relevant function from `ski.util`. Speaking of `ski`, les look at how to apply this filter in `skimage` in the next section..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c52eb13",
   "metadata": {},
   "source": [
    "# Histogram equalisation in `skimage`\n",
    "\n",
    "As normal, `skimage` makes it easy to implement this filter, in just a single line of code. We just pass our `eagle` image to the `ski.exposure.equalize_hist()` function, and it will carry out all we saw above, behind the scenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3cadf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equalise `eagle` using `skimage.\n",
    "eagle_equalized_with_ski = ski.exposure.equalize_hist(eagle)\n",
    "\n",
    "# Generate the plot.\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(eagle)\n",
    "plt.title('Original Image')\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(eagle.ravel(), bins=128)\n",
    "plt.title('Original Histogram')\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(eagle_equalized_with_ski)\n",
    "plt.title('Equalised Image (via `skimage`)')\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.hist(eagle_equalized_with_ski.ravel())\n",
    "plt.title('Equalised Histogram (via `skimage`)')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7028e7f6",
   "metadata": {},
   "source": [
    "Easy peasy. If you consult the [documentation](https://scikit-image.org/docs/0.25.x/api/skimage.exposure.html#skimage.exposure.equalize_hist) for `ski.exposure.equalize_hist()`, you notice that by default, it uses 256 bins. In fact, for the `nbins` optional argument, the documentation states that it will be ignored for integer data. This is so the \"indexing trick\" that we saw above can be performed. \n",
    "\n",
    "It is no problem to use this filter with `float` image data however - the principle is the same pixel intensities get mapped to their corresponding cumulative proportion. Only now this occurs without the neat indexing trick, there is just an intermediate (boring!) step in the mapping. We demonstrate this below with the `coins` image from `ski.data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182d024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the `coins` image.\n",
    "coins = ski.data.coins()\n",
    "\n",
    "# Convert to `float64` `dtype`.\n",
    "coins_as_float = ski.util.img_as_float64(coins)\n",
    "\n",
    "# Show the image, the histogram of the image, and the attributes of the image.\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(coins_as_float)\n",
    "plt.title('Original Image')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(coins_as_float.ravel())\n",
    "plt.title('Original Histogram')\n",
    "plt.tight_layout();\n",
    "show_attributes(coins_as_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d5392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equalise the histogram.\n",
    "coins_as_float_equalised_with_ski = ski.exposure.equalize_hist(coins_as_float)\n",
    "\n",
    "# Show the image, the histogram of the image, and the attributes of the image.\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(coins_as_float_equalised_with_ski)\n",
    "plt.title('Equalised Image (via `skimage`)')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(coins_as_float_equalised_with_ski.ravel())\n",
    "plt.title('Equalised Histogram (via `skimage`)')\n",
    "plt.tight_layout();\n",
    "show_attributes(coins_as_float_equalised_with_ski)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3b7e9d",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "This page has shown a local filter (the median filter) and a non-local filter (histogram equalisation) which do not use convolution to perform their filtering operations. On the [next page](8_morphology) we will introduce another method for modifying pixels based on a `footprint`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79674074",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "3.3.5 onward from: https://lectures.scientific-python.org/packages/scikit-image/index.html\n",
    "\n",
    "Based on: https://scikit-image.org/skimage-tutorials/lectures/1_image_filters.html\n",
    "\n",
    "Histogram equalisation adapted from: https://www.janeriksolem.net/histogram-equalization-with-python-and.html\n",
    "\n",
    "Histogram equalisation: https://medium.com/jungletronics/histogram-equalization-34149fc299a6\n",
    "\n",
    "Reference: https://www.kdnuggets.com/numpy-for-image-processing\n",
    "\n",
    "Reference: https://setosa.io/ev/image-kernels\n",
    "\n",
    "Reference: https://wiki.imindlabs.com.au/ds/aml/4_problem_domains/1-image-processing/3_edge_detectors\n",
    "\n",
    "Reference: https://www.geeksforgeeks.org/deep-learning/types-of-convolution-kernels\n",
    "\n",
    "Reference: skimage tutorials (check versions), scipy lecture notes\n",
    "\n",
    "Reference: https://jni.github.io/i2k-skimage-napari/lectures/1_image_filters.html"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python (Pyodide)",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
